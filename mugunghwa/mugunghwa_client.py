import cv2
import time
import socket
import numpy as np
import pyrealsense2 as rs
from openpose import pyopenpose as op
from gtts import gTTS
import os
import random

# ìŒì„± ì¶œë ¥ í•¨ìˆ˜ (TTS)
def speak(text, speed='normal'):
    tts = gTTS(text=text, lang='ko', slow=(speed == 'slow'))
    tts.save("output.mp3")

    if speed == 'fast':
        os.system("mpg123 --pitch +1 output.mp3")
    elif speed == 'slow':
        os.system("mpg123 output.mp3")
    else:
        os.system("mpg123 output.mp3")

# ê±°ë¦¬ ë³´ì • í•¨ìˆ˜
def get_stable_distance(depth_frame, x, y, window=2):
    depths = []
    width = depth_frame.get_width()
    height = depth_frame.get_height()
    for dx in range(-window, window + 1):
        for dy in range(-window, window + 1):
            nx, ny = x + dx, y + dy
            if 0 <= nx < width and 0 <= ny < height:
                d = depth_frame.get_distance(nx, ny)
                if 0.1 < d < 10.0:
                    depths.append(d)
    if depths:
        return sum(depths) / len(depths)
    else:
        return 0.0

# ì„œë²„ ì—°ê²°
def connect_to_server(host='127.0.0.1', port=5000):
    try:
        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        s.connect((host, port))
        s.sendall("KJH".encode())
        print("[ì„œë²„ ì—°ê²° ì„±ê³µ ë° ID ì „ì†¡ ì™„ë£Œ]")
        return s
    except Exception as e:
        print("[ì„œë²„ ì—°ê²° ì‹¤íŒ¨]:", e)
        return None

# OpenPose ì´ˆê¸°í™”
params = {"model_folder": "models/", "model_pose": "BODY_25"}
op_wrapper = op.WrapperPython()
op_wrapper.configure(params)
op_wrapper.start()

# RealSense ì¹´ë©”ë¼ ì´ˆê¸°í™”
pipeline = rs.pipeline()
config = rs.config()
config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
pipeline.start(config)

motion_threshold = 50
victory_distance = 0.7

server_socket = connect_to_server()
if not server_socket:
    exit()

print("ê²Œì„ ì‹œì‘ ëŒ€ê¸° ì¤‘: ì„œë²„ë¡œë¶€í„° 'ë¬´ê¶í™”' ëª…ë ¹ì„ ê¸°ë‹¤ë¦½ë‹ˆë‹¤...")

try:
    while True:
        data = server_socket.recv(1024).decode().strip()
        if data == "ë¬´ê¶í™”":
            print("[ì„œë²„] 'ë¬´ê¶í™”' ìˆ˜ì‹ ë¨. ê²Œì„ ì‹œì‘ ê°€ëŠ¥.")
            break
        else:
            print("[ì„œë²„ ìˆ˜ì‹  ëŒ€ê¸° ì¤‘] í˜„ì¬ ìˆ˜ì‹ :", data)
except Exception as e:
    print("[ì„œë²„ ìˆ˜ì‹  ì˜¤ë¥˜]:", e)
    server_socket.close()
    exit()

print("ê²Œì„ ì‹œì‘: 'c' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ê²Œì„ ì‹œì‘")
print("ì›€ì§ì´ì§€ ì•Šê³  ì¹´ë©”ë¼ì— ê°€ê¹Œì´ ë‹¤ê°€ê°€ë©´ ìŠ¹ë¦¬!")

try:
    while True:
        frames = pipeline.wait_for_frames()
        depth_frame = frames.get_depth_frame()
        color_frame = frames.get_color_frame()
        if not depth_frame or not color_frame:
            continue

        color_image = np.asanyarray(color_frame.get_data())
        datum = op.Datum()
        datum.cvInputData = color_image
        datums = op.VectorDatum()
        datums.append(datum)
        op_wrapper.emplaceAndPop(datums)

        cv2.imshow("OpenPose", datums[0].cvOutputData)
        key = cv2.waitKey(1) & 0xFF

        if key == ord('c'):
            speed = random.choice(['fast', 'normal', 'slow'])
            speak("ë¬´ê¶í™” ê½ƒì´ í”¼ì—ˆìŠµë‹ˆë‹¤", speed)
            print(f"[TTS] ì†ë„ = {speed}")

            print("[LCD] ë¬´ê¶í™” ê½ƒì´ í”¼ì—ˆìŠµë‹ˆë‹¤.")

            wait_start = time.time()
            while time.time() - wait_start < 5:
                frames = pipeline.wait_for_frames()
                color_frame = frames.get_color_frame()
                color_image = np.asanyarray(color_frame.get_data())
                remaining = int(5 - (time.time() - wait_start))
                cv2.putText(color_image, f"Starting in {remaining}s", (10, 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
                cv2.imshow("OpenPose", color_image)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break

            print("[LCD] ìˆ ë˜ê°€ ë‹¹ì‹ ì„ ë³´ê³  ìˆìŠµë‹ˆë‹¤!")
            print("3ì´ˆê°„ ì›€ì§ì´ì§€ ë§ˆì‹­ì‹œì˜¤!")

            pose_sum = []
            start_time = time.time()
            while time.time() - start_time < 3:
                frames = pipeline.wait_for_frames()
                depth_frame = frames.get_depth_frame()
                color_frame = frames.get_color_frame()
                color_image = np.asanyarray(color_frame.get_data())

                datum = op.Datum()
                datum.cvInputData = color_image
                datums = op.VectorDatum()
                datums.append(datum)
                op_wrapper.emplaceAndPop(datums)

                keypoints = datums[0].poseKeypoints
                if keypoints is None or len(keypoints.shape) < 3:
                    continue

                person = keypoints[0][:, :2]
                pose_sum.append(person)

                cv2.putText(datums[0].cvOutputData, "Soolrae is watching...", (10, 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)
                cv2.imshow("OpenPose", datums[0].cvOutputData)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break

            moved = False
            for i in range(1, len(pose_sum)):
                diffs = np.linalg.norm(pose_sum[i] - pose_sum[i - 1], axis=1)
                mean_movement = np.mean(diffs)
                if mean_movement > motion_threshold:
                    moved = True
                    break

            if moved:
                print("Game Over: ì›€ì§ì„ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                server_socket.sendall("Game Over".encode())
                continue
            else:
                print("ì›€ì§ì´ì§€ ì•ŠìŒ í™•ì¸. ì „ì§„ ì‹œì‘!")

            success_count = 0
            while True:
                frames = pipeline.wait_for_frames()
                depth_frame = frames.get_depth_frame()
                color_frame = frames.get_color_frame()
                color_image = np.asanyarray(color_frame.get_data())

                datum = op.Datum()
                datum.cvInputData = color_image
                datums = op.VectorDatum()
                datums.append(datum)
                op_wrapper.emplaceAndPop(datums)

                keypoints = datums[0].poseKeypoints
                if keypoints is None or len(keypoints.shape) < 3:
                    continue

                person = keypoints[0]
                x = int((person[1][0] + person[8][0]) / 2)
                y = int((person[1][1] + person[8][1]) / 2)

                distance = get_stable_distance(depth_frame, x, y)

                if distance == 0.0:
                    print("ê±°ë¦¬ ì •ë³´ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŒ, ë‹¤ì‹œ ì¸¡ì • ì¤‘...")
                    success_count = 0
                    continue

                print(f"í˜„ì¬ ê±°ë¦¬: {distance:.2f}m")
                cv2.putText(datums[0].cvOutputData, "Move forward...", (10, 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
                cv2.putText(datums[0].cvOutputData, f"Distance: {distance:.2f}m", (10, 65),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)

                if distance < victory_distance:
                    success_count += 1
                    if success_count >= 2:
                        print("ğŸ‰ Victory! ë„ì°©í–ˆìŠµë‹ˆë‹¤.")
                        server_socket.sendall("Victory".encode())
                        break
                else:
                    success_count = 0

                cv2.imshow("OpenPose", datums[0].cvOutputData)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break

        elif key == ord('q'):
            break

finally:
    server_socket.close()
    pipeline.stop()
    cv2.destroyAllWindows()
